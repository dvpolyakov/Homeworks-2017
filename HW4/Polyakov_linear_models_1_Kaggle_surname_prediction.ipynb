{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче нужно построить классификатор, который может определить, является ли слово фамилией или нет. Обучающая выборка - список слов, размеченный 0 и 1 (1 - если является фамилией, 0 иначе)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word          object\n",
       "is_surname     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.txt', header=0, sep=',', encoding = 'utf-8')\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(train.Word, train.is_surname, test_size = 0.1, stratify = train.is_surname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22687      Долларом\n",
       "62187       ПОДОБИИ\n",
       "88959         Уайлс\n",
       "19553       дверцах\n",
       "79210    слабоволия\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составляем список всех слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "L = len(train_data)\n",
    "for i in range(L):\n",
    "    corpus.append(train_data.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Долларом', 'ПОДОБИИ', 'Уайлс', 'дверцах', 'слабоволия', 'ДЕЛОПРОИЗВОДИТЕЛЬ', 'мореходам', 'молитвеннику', 'Ингмару', 'Александрам']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея решения - использовать в качестве признаков слов их n-граммы (по сути one-hot-encoding). Для разбиения используем CountVectorizer. Размер n-грамм выберем от 1 до 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"vectorizer\", CountVectorizer(analyzer = 'char_wb', min_df=1, ngram_range=(1, 8), lowercase = False)), (\"algo\", LogisticRegression(penalty = 'l2', max_iter = 300, solver = 'lbfgs'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 8), preprocessor=None, stop_words=None,\n",
       "   ...enalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92310617764\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels, pipeline.predict_proba(test_data)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также заметим, что дополнительно можно использовать, например, такие признаки: является ли первая буква заглавной, написано ли все слово капсом. Можель была протестирована с этими признаками. Качество на кросс валидации почти не улучшилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На кросс-валидации хорошее качество. Можно запускать алгоритм на тестовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично из тестовых данных делаем корпус слов и передаем в уже обученный pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_df = pd.read_csv(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = real_df.Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Аалто\n",
       "1      ААР\n",
       "2     Аара\n",
       "3     Ааре\n",
       "4    Аарон\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_corpus = []\n",
    "L = len(real_data)\n",
    "for i in range(L):\n",
    "    real_corpus.append(real_data.iloc[i].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика в задаче - плошадь под AUC-ROC кривой. Поэтому нам нужны вероятности принадлежности слов из теста к классу 1 (фамилии)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict_proba(real_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.92661493  0.07338507]\n",
      " [ 0.9540203   0.0459797 ]\n",
      " [ 0.95914389  0.04085611]\n",
      " [ 0.98913298  0.01086702]\n",
      " [ 0.93468895  0.06531105]\n",
      " [ 0.96019346  0.03980654]\n",
      " [ 0.95782701  0.04217299]\n",
      " [ 0.95580892  0.04419108]\n",
      " [ 0.95580892  0.04419108]\n",
      " [ 0.96380841  0.03619159]]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188920\n"
     ]
    }
   ],
   "source": [
    "print(len(real_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188920\n"
     ]
    }
   ],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Id</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалто</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ААР</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аара</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ааре</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарон</td>\n",
       "      <td>4</td>\n",
       "      <td>0.065311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Аароне</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ааронов</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Аароном</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Аароном</td>\n",
       "      <td>8</td>\n",
       "      <td>0.044191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Аарону</td>\n",
       "      <td>9</td>\n",
       "      <td>0.036192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Аарону</td>\n",
       "      <td>10</td>\n",
       "      <td>0.036192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Аахен</td>\n",
       "      <td>11</td>\n",
       "      <td>0.018941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Аахене</td>\n",
       "      <td>12</td>\n",
       "      <td>0.008853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Аахеном</td>\n",
       "      <td>13</td>\n",
       "      <td>0.011051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>АБ</td>\n",
       "      <td>14</td>\n",
       "      <td>0.009159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Абадан</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Абадане</td>\n",
       "      <td>16</td>\n",
       "      <td>0.001484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Абаданом</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Абаев</td>\n",
       "      <td>18</td>\n",
       "      <td>0.214486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Абаева</td>\n",
       "      <td>19</td>\n",
       "      <td>0.610988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Абаевым</td>\n",
       "      <td>20</td>\n",
       "      <td>0.798440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Id    Answer\n",
       "0      Аалто   0  0.073385\n",
       "1        ААР   1  0.045980\n",
       "2       Аара   2  0.040856\n",
       "3       Ааре   3  0.010867\n",
       "4      Аарон   4  0.065311\n",
       "5     Аароне   5  0.039807\n",
       "6    Ааронов   6  0.042173\n",
       "7    Аароном   7  0.044191\n",
       "8    Аароном   8  0.044191\n",
       "9     Аарону   9  0.036192\n",
       "10    Аарону  10  0.036192\n",
       "11     Аахен  11  0.018941\n",
       "12    Аахене  12  0.008853\n",
       "13   Аахеном  13  0.011051\n",
       "14        АБ  14  0.009159\n",
       "15    Абадан  15  0.001412\n",
       "16   Абадане  16  0.001484\n",
       "17  Абаданом  17  0.001684\n",
       "18     Абаев  18  0.214486\n",
       "19    Абаева  19  0.610988\n",
       "20   Абаевым  20  0.798440"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df['Id'] = np.arange(len(real_df))\n",
    "real_df['Answer'] = preds[:, 1] \n",
    "real_df.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем в файл, оставив только id слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_df = real_df.drop('Word', 1)\n",
    "real_df.to_csv(\"subm.txt\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
